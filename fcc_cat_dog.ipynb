{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la_Oz6oLlub6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # This command only in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaF8r6aOl48C"
      },
      "outputs": [],
      "source": [
        "# Get project files\n",
        "!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
        "\n",
        "!unzip cats_and_dogs.zip\n",
        "\n",
        "PATH = 'cats_and_dogs'\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "\n",
        "# Get number of files in each directory. The train and validation directories\n",
        "# each have the subdirecories \"dogs\" and \"cats\".\n",
        "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
        "total_test = len(os.listdir(test_dir))\n",
        "\n",
        "# Variables for pre-processing and training.\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EOJFeEfumns6",
        "outputId": "00e36dba-1692-42ab-dc8c-e0201fefd309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 50 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# 3\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths (update these to match your actual directory structure)\n",
        "base_dir = '/content/cats_and_dogs'  # Main directory containing train/validation/test\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')  # Test directory contains images directly\n",
        "\n",
        "# Image parameters\n",
        "batch_size = 32\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "# Create image generators\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create data generators\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=test_dir,  # Changed from 'directory' to test_dir\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    classes=[''],  # Important for test directory structure\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP0WA8j1mt7Q"
      },
      "outputs": [],
      "source": [
        "# 4\n",
        "def plotImages(images_arr, probabilities = False):\n",
        "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
        "    if probabilities is False:\n",
        "      for img, ax in zip( images_arr, axes):\n",
        "          ax.imshow(img)\n",
        "          ax.axis('off')\n",
        "    else:\n",
        "      for img, probability, ax in zip( images_arr, probabilities, axes):\n",
        "          ax.imshow(img)\n",
        "          ax.axis('off')\n",
        "          if probability > 0.5:\n",
        "              ax.set_title(\"%.2f\" % (probability*100) + \"% dog\")\n",
        "          else:\n",
        "              ax.set_title(\"%.2f\" % ((1-probability)*100) + \"% cat\")\n",
        "    plt.show()\n",
        "\n",
        "sample_training_images, _ = next(train_data_gen)\n",
        "plotImages(sample_training_images[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-32RRLY_3voj"
      },
      "outputs": [],
      "source": [
        "# 5\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkwq2LFvqabS"
      },
      "outputs": [],
      "source": [
        "# 6\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8aZkwMam4UY"
      },
      "outputs": [],
      "source": [
        "# 7\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1niQDz5x6K7y"
      },
      "outputs": [],
      "source": [
        "# 8\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xS51mB56OAC"
      },
      "outputs": [],
      "source": [
        "# 9\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MqLNoERIBix"
      },
      "outputs": [],
      "source": [
        "# 10\n",
        "test_data_gen.reset()\n",
        "probabilities = model.predict(test_data_gen, steps=np.ceil(50/batch_size))\n",
        "probabilities = probabilities.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4IH86Ux_u7TZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e458bfad-af70-433a-b08b-3f806a69540f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'probabilities' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3c1851b48bfb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'probabilities' is not defined"
          ]
        }
      ],
      "source": [
        "# 11\n",
        "answers =  [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "            1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
        "            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
        "            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
        "            0, 0, 0, 0, 0, 0]\n",
        "\n",
        "correct = 0\n",
        "\n",
        "for probability, answer in zip(probabilities, answers):\n",
        "  if round(probability) == answer:\n",
        "    correct +=1\n",
        "\n",
        "percentage_identified = (correct / len(answers)) * 100\n",
        "\n",
        "passed_challenge = percentage_identified >= 63\n",
        "\n",
        "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
        "\n",
        "if passed_challenge:\n",
        "  print(\"You passed the challenge!\")\n",
        "else:\n",
        "  print(\"You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_cat_dog.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}